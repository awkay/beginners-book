= Introduction to Programming
:author: Tony Kay
:lang: en
:encoding: UTF-8
:doctype: book
:source-highlighter: coderay
:source-language: clojure
:toc: left
:toclevels: 3
:sectlinks:
:sectanchors:
:leveloffset: 1
:sectnums:
:imagesdir: assets/img
:scriptsdir: js
:imagesoutdir: docs/assets/img
:favicon: assets/favicon.ico

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

ifdef::env-github[]
toc::[]
endif::[]

= Thinking About Information

== Without Computers

In normal everyday life there are lots of ways we represent information that do not involve computers. We use
paper, ink, film, photographic paper, sticks and sand, etc. The information can be small and transient
(a heart drawn on a sandy beach with a stick) or quite large with an emphasis on access and permanence
(The Library of Congress).  We might also be concerned with the physical space required for that information. The
use of microfilm which predated the common availability of computers was very often used to store things like
old newspapers, for example.

We humans choose the representation of this information based on many factors:
space, speed of access, permanence.

* A dictionary is sorted so that you can predictably skip huge swaths of words to get to what you want.
* Libraries order their books and provide a catalogue to optimize search AND minimize walking.
* Newpapers were put on microfilm to dramatically reduce storage required.

In the pre-digital world it is very easy to conceptualize all of these things because we can see the physical objects:
A dictionary, a library, a stick being used on a sandy beach.

== With Computers

As we moved into the digital realm, we needed to invent ways to represent this same information there.
This brave new world requires a big shift, because digital computers primarily deal with numbers. So, the
field of computer science is largely a field of applied mathematics where we search for ways to represent
real-world information as numbers. There are probably *many* more ways to encode data as numbers as
there are to encode them physically.

Fortunately, the same basic concerns exist in the digital realm:

* Space: We've all probably filled up a hard drive.
** Compression: (paper vs microfilm)
* Speed of Access
* Permanence (power on, power off)

When learning about information representation in computers, we're largely learning just a few things:

* What low-level ways can the computer actually represent the information?
** This is usually just some encoding from a easy-to-use human form to a numeric form.
** Programming languages usually have features that were developed to make that conversion easier for programmers to do.
* What creative ways can we use to organize the information for fast or convenient access?
** Algorithms: a process or set of rules to be followed in calculations or other problem-solving operations
such as data encoding/decoding.
* Permanence: Once we have the numbers, where do we keep them? Can we make them smaller?

Obviously, at this point and time we have gone far beyond requiring you the programmer from looking
at the low-level numbers in the computer itself. Modern programming languages do a lot to make
the basic data representation easy.

QUIZ::
What are the common desires that we hope to meet in both the old-world representation and the digital representation?

== Common Basic Data

All digital computers end up doing about the same thing. There are, however, hundreds of programming languages
in use today that are targeted at making particular tasks easy for a subset of the population.

For example, a spreadsheet is actually a kind of programming language (just the ability to have cells based on the
values of other cells with formulas). This language is quite useful to all sorts of people.

The BASIC programming language was invented as something beginners could easily write simple things in.

These languages are all trying to do one basic thing: Take text that *you* write and turn it into something the
computer can understand. These programming languages are themselves inventions of people before you
and themselves are programs whose one job is to translate one language into the language of the computer.

As such, all of these language have invented things that you type that can be turned into raw data for
the computer.

We'll cover a few of those here.

QUIZ::
Since different programming languages have different things you might "type" in order to represent data, do
you imagine that many of these languages would share some commonalities? Name some that you would expect to
be close or identical in many programming languages.

=== Integers

Whole (signed) numbers are usually just typed as-is: 4 means 4.

Computers actually store integers using binary, which means the low-level representation uses
math based on powers of two. Because of this we sometimes use alternative ways of typing them
into a programming language. The base-10 numbers are always written as normal numbers.

Sometimes we switch to using base-16, sometimes called hexidecimal, or just hex. There
are two reasons for this: It is shorter to type, and we can more easily convert the number to the
underlying bit pattern because each digit of a hex number represents 4 bits.  The letter `A` is used
for the "extra" digit `10`, `B` = `11`, up to `F` = 15 (for a total of 16 possibilities per digit).

If you were trying to write down a number that matched a particular "bit pattern" in computer memory
you might want to do the conversion like this:

|===
| Binary| 0101  | 1010  | 0111
| Hex |    5    | A     |    7
|===

We usually write hex in programming languages by prefixing the digits with `0x`. So in this example, the
hex number is typed into the computer as `0x5A7`. If you use a programmer's calculator you can convert this
to decimal.

QUIZ::
What is 0x5A7 in decimal?

BONUS::
Octal (only using digits 0 to 7) happens to align on 3-bit boundaries. In programming languages octal
can usually be typed in by prefixing the number with `0`. For example, `013` is an octal number in
many languages, NOT a decimal. Convert the bit pattern from the example in this section into octal.

=== Decimal Numbers

Numbers that have a decimal point have to be stored using a different bit pattern than integers. We won't
cover the details of that here, but most programming languages support two different "sizes" of decimal
numbers. The term used for these is usually "floating point number" ("float" for short) and
"double precision floating point number" ("double" for short).

How standard floating point numbers are stored and work in computers is defined by an IEEE-754 standard.
Any language you are likely to work in is running on a computer that uses this standard, though
there can be some variance as your platform gets exotic.

Programming languages usually define "float" as a 32-bit version, which can store numbers with
7 digits of precision, and can slide the decimal place left/right about 38 places. A "double" uses
64 bits, and has 15 digits of precision, and can slide the decimal place roughly 308 places (i.e.
the biggest number is about stem:[10^308])

A suffix is often supported in programming languages when typing a number if you wish to clarify
the representation you want.

|====
|Language| What you type| What you get
| Clojure | 3.5 | double
| Clojure | (float 3.5) | float
| Java | 3.5  | double
| Java | 3.5f  | float
| Javascript | 3.5  | double (no way to get float)
|====

=== Characters

A character is a glyph (usually appearing on, or producible by a keyboard) that has some human meaning. The
early American computers could only support the characters used in North America. The ASCII standard was
the first mapping from human glyphs (like the capital letter A) to numbers (65).

|===
|Language | What you'd type
|C |'A' |
|C++ |'A'
|Clojure | \A
|ClojureScript | \A
|Java |'A'
|Javascript | No direct way to type in a single character (see strings)
|===

as you can see many languages have overlap in how you'd represent a single glyph.

ASCII is just one *encoding* (glyph to number). Today most modern languages are meant to be used internationally.
Unfortunately, until a standard was reached globally, every country in the world invented their own encoding. This
was a real mess for a while. You can go look at these older (and still supported) encodings, such as
the one that was used for https://en.wikipedia.org/wiki/ISO/IEC_8859-7[greek].

Most programmers today use Unicode. For space constraints most Unicode is stored as UTF-8, which just means that
each glyph you type uses at least 8 bits (one byte) but can use more bytes if needed. Chinese has many thousands of glyphs,
so to truly represent every possible glyph may require a few bytes. UTF-8 is an example of two things: the encoding of
information, and also the *compression* of that information.  UTF-8 takes no more space than ASCII if you only use
plain English, but if you use Chinese it automatically uses the additional space needed store the larger
numbers that those glyphs encode to.

For example, in UTF-8, an 'A' is still the number 65 (a single byte), but the greek letter π is stored as
two bytes holding the numbers 207, followed by 128.

QUIZ:: Type "UTF for π" into google search. It should show you the UTF-8, 16, and 32 values. Do you notice anything odd
between those? What? If you see something odd, can you explain it?

BONUS::
What is the decimal number used in UTF-8 (and ASCII) for the lower-case letter `a`? What's the numerical difference
between `A` and `a`? Think about that in binary: How might that be significant?

=== Strings

The word "string" in computing is playing on the idea of "stringing things together". Basically a string in
a computer is simply a linear sequence of characters, which either starts with a "length", or ends with a
special termination value (usually called NUL, which is almost always the number 0).

So, the string that contains three `A`'s in a row would be stored in the computer either as the length
followed by the character codes:

|====
|  3     |  65  |  65  |  65
|====

or more commonly as the characters with a NUL termination:

|====
|  65  |  65  |  65 | 0
|====

You will often hear the latter called "null-terminated strings". You will often hear or see this idea
discussed using the terms/symbols null, NUL, ø.

NOTE: There are, of course, more ways of storing strings in computers.

As far as what *you* type in the programming language, it is usually the sequence of glyphs surrounded by
`"`. E.g. "Hello world" is typically a null-terminated string containing those character codes.

All programming languages have a way to treat a string as a sequence of some sort. In other words, you can
usually access the individual characters, or grab a range of them.

|====
| Language | What you type |What you get
| C | "Hello world" | An ASCII encoded, null-terminated string
| Java/Clojure | "Hello world" | A UTF-8 encoded, null-terminated string
| Javascript | "Hello world" | A UTF-16 (!!!), null-terminated string
| Javascript | 'Hello world' | A UTF-16 (!!!), null-terminated string
|====

Note that in Javascript there are *two* ways to get a string. That language expects there to be the need
to often embed quotes within quotes, so it was deemed convenient to be able to type `"he's over there"`
or `'"Hello", she said.'`

Anytime you need to embed the "start quote" character within a string, most langauges simply have you
prefix it with `\`. For example, in Java or Clojure you'd type `"\"Hello\", she said"` to get a string
that also includes the literal character `"`.

QUIZ::
We know that in Java/Clojure `"AA"` is represented in memory as the null-terminated string of numbers 65, 65, 0.
What would be the sequence of in-memory numbers for the string `"A π"`? Hint: Remember to look up the encoding for
the space!

QUIZ::
In Clojure what would you type in to make a literal string out of:
`Javascript uses both ' and " to surround strings`.

BONUS::
Can you guess why strings are usually stored with NUL termination instead of a prefix length? What
do you think are the advantages/disadvantages of these two ways of storing strings?

==== Special Characters in Strings

Strings are one of the most commonly-used things in programming, so it pays to know a little more about them.
In *most* programming languages you *cannot* put a line break inside of the string. For example, this is an
error in Java, Javascript, C, C++, and most other languages:

[source,java]
-----
"This is a test
 Hello!"
-----

NOTE: Clojure and Clojurescript are *ok* with putting a literal new line in a string like that.

Instead, most programming languages define a way in which you can embed control characters in a more visible way. The
method of doing this is *just* like the method for embedding a quote within quotes: use a `\`. The most common
special embedded things are: `\n` (newline), `\r` (Windows, carriage return, old typewriter garbage), `\t` TAB. In
many programming languages the special `\u0000` means to use a literal unicode value (e.g. π can be typed into
a string as "\u03C0" in Java and Clojure).

So, in Java you'd change the broken example above to:

[source,java]
-----
"This is a test\n Hello!"
-----

QUIZ::
What would you type into Java in order to get the words "Happy Birthday Sally" on three different lines? It turns out
this answer is slightly different on Windows vs. everything else (OSX, Linux, UNIX). What is it on Windows?

=== Arrays

Arrays are exactly like strings (they are a sequence of things that are adjacent
in the computer's memory), except they are something besides characters.

Technically an array is: A fixed-length sequence of equal-sized entries, laid out
so the values are adjacent and sequential in computer memory.

Making an array varies by language. For example, to create an array of floats called `arr`:

|=====
| Language | Make a new array called `arr`
| Java | float arr[] = new float[3];
| Javascript | var arr = new Float32Array(3);
| Clojure | (def arr (float-array 3))
|=====

which results in this in the computer's memory:

[ditaa,target=arr1]
-----
offset +---------+
    0  | float   |
       +---------+
    1  | float   |
       +---------+
    2  | float   |
       +---------+
-----

Where the numbers to the left of each box are the *offset* of a given entry.
Programming languages will give you a way to read/write the cells of an array
by this "abstract offset".

For example:

|=====
| Language | Get an element from an array | Set an element of an array
|  C          | b = arr[1]     | arr[1] = 3.4f
|  Java       | b = arr[1]     | arr[1] = 3.4f
|  Javascript | b = arr[1]     | arr[1] = 3.4f
|  Clojure    | (aget arr 1)   | (aset arr 1 3.4f)
|=====

and after the set operation (e.g. `arr[1] = 3.4f`) we'll have this:

[ditaa,target=arr2]
-----
offset +---------+
    0  | ???     |
       +---------+
    1  | 3.4     |
       +---------+
    2  | ???     |
       +---------+
-----

To advance your understanding, note that each byte
of computer's memory is actually "indexed" by its relative location in the computer chip. So, if
you have 1GB of memory (1 billion bytes), then by definition you have a byte with address 0,
a byte with address 1, 2, 3, ..., 1 billion.

When you create an array, you're asking the programming language to find a block of this memory that
is not currently in use, and then you're asking it to produce the correct instructions to read/write
the data in that block. So, say our computer had some free space at address 1024, then
our array of floats actually looks something like this in memory:

[ditaa,target=arrdetail]
-----
            the bit pattern of floats is "4 bytes wide"
address   +---------+ +---------+ +---------+ +---------+
     1024 | 11010101| | 01001011| | 11001111| | 11010110|
          +---------+ +---------+ +---------+ +---------+

          +---------+ +---------+ +---------+ +---------+
     1028 | 11010101| | 01001011| | 11001111| | 11010110|
          +---------+ +---------+ +---------+ +---------+

          +---------+ +---------+ +---------+ +---------+
     1032 | 11010101| | 01001011| | 11001111| | 11010110|
          +---------+ +---------+ +---------+ +---------+
-----

The idea of a linear sequence of the "same kind of" things in the computer's memory is
actually quite useful for a few reasons:

. It allows you to store more than one thing as a "group"
. Since the items are all the same size the computer can figure out exactly where
ANY element is with just an offset (stem:[position = offset * size_{entry}]).

This allows you to "jump" to any spot in the array in the computer's memory in constant time
and computers are quite good at this sort of thing. Accessing a given direct address with a primitive
(in this case float) format can usually be done in a matter of nanoseconds! This means you
can literally do billions of these operations per second!

NOTE: An operation that can be run with some small fixed-size number of instructions is said to run
in "constant time". This is often annotated in computer science as O(1). The idea is to express
the relative speed of something (given an idealized computer) relative to other kinds of operations
that might produce the same result. Constant time algorithms are the fastest, but comparing
two different constant time algorithms, of course, might yield a different actual run-time. For example,
the function to convert Fahrenheit to Centigrade is a constant time function, but since it involves
a few math operations it might be a bit slower than an array access.

Arrays are the most basic *collection* of data in most programming languages, and while very
fast and compact they have some drawbacks (the bonus question has you explore this).
Newer programming languages support them for their size/speed, but usually define and use
more advanced collections for various reasons.

QUIZ::
Do arrays have to be contiguous in memory?

BONUS::
If you need to "expand" an array (i.e. you run out of space and need to hold more things)
and the computer has no free memory *right next to* the old array, what would you have
to do in order to be able to use a bigger array? If the array way already quite large
would this cause you concerns? Why?

BONUS::
Say you have an array that can hold 1000 float. You've initialized 600 of them (so the last 400
don't yet have values you care about). You realize that you to INSERT an element at offset
50, but you don't want to *overwrite* the value that is there. You want to keep the existing good
data. What do you have to do? Thoughts about this?

==== Relation to Strings

Arrays and strings, as you might have guessed, are very similar.

In fact, some programming languages (C and C++) explicitly *use* arrays of characters AS
strings in their formal definition.

Many more modern languages define strings as a separate conceptual thing, even though they
are usually stored as an array of characters internally.

The reason we treat arrays and strings as different things in most languages has to do with how
we'll commonly use them. Strings are almost always used for human-readable content that
will be shown with some font on a display or printer, or for portions of input documents that the
computer will process by interpreting the data through a character encoding.

So, you can think of a string as an "array of characters" (though your programming language may
not allow you "program it that way" for safety).

QUIZ::
Say you write a program to process the data in the file. What do you suppose happens if your program
assumes that data is encoded as UTF-8 string data, but the file is actually encoded with
a historical encoding like the one used for greek?

== More Advanced Data Structures

Formally, a data structure in programming is an invention of Computer Science aimed at the
efficient storage and retrieval of information. Arrays, as covered in the prior section,
are perhaps the most basic data structure.

If you did the exercises then you already know the weaknesses of arrays:

* It is expensive to insert something into the middle. (you have to copy the "tail" over 1 if you have space,
and otherwise copy the whole thing)
* It is expensive when you run out of the pre-allocated size of the array (you have to copy the entire thing
to a new place)

Another weakness of arrays is their limited organization. You have numerical offsets as keys. What if you're
trying to look up things by a person's name, or a book's title? How would you convert a "name" into an
"offset"? (Actually, there's a good and useful answer to that, which is yet another fun invention of
Computer Science).

But suffice to say that arrays are not the best tool for every job. In fact, arrays are often only used in
high performance applications where their limitations can be dealt with in a constrained way.

So, what else do we have in our toolbox? Let's see.

=== Linked Lists

A linked list, when drawn out, is a very simple thing:

[ditaa,target=linkedlist]
-----
   +---+   +---+   +---+   +---+
   | A +-->| B +-->| C +-->| D +-> ø
   +-+-+   +-+-+   +-+-+   +-+-+
-----

We allocate individual "chunks" of memory that we refer to as "nodes". Each node has internal storage that can
hold a value. In Clojure, the type of this value can be "anything".  Each node also has a "pointer" to the
next chunk of memory that holds data for the list. We "terminate" the list the same way we terminate strings. With
a value we refer to as "null" (in clojure "null" is written as `nil`).

The memory for a node can be allocated at any time, and because
of the "pointer" structure, it need not be contiguous in memory like it has to be for an array.

So, the clear advantage of a linked list is that it can expand in "constant time". There is no need to copy
any old elements anywhere. Simply make a new node and point it's "next node" pointer at the old list:

[ditaa,target=linkedlistadd]
-----
   +---+   +---+   +---+   +---+   +---+
   | N +-->| A +-->| B +-->| C +-->| D +-> ø
   +---+   +-+-+   +-+-+   +-+-+   +-+-+
-----

It is also technically possible to put a new bit of data "in the middle" by just re-routing the pointers:

[ditaa,target=linkedlistinsert]
-----
   +---+   +---+   +---+   +---+
   | A +-->| B +   | C +-->| D +-> ø
   +---+   +-+-+   +---+   +-+-+
             |       ^
             |       |
             |     +-+-+
             +---->| N |
                   +---+
-----

Of course there are down-sides:

* To "read" a node at some offset, you must manually step through each node, tracking how many steps you've taken,
and then read the data from the node you eventually get to.
* Inserting a node or appending to the "end" are also proportional to the number of items in the list.

NOTE: This concept of a process taking some number of steps that is proportional to the number of data items is known as a "linear time algorithm", which basically means each such operation costs an amount of time proportional to the
size of the data being stored. This is usually written O(n) to indicate it runs in a time proportional to the number
`n` of items in the target. Notice that like O(1) this is simply used to specify a rough idea about relative speed.

In languages like Java and C++ linked lists are provided in several variants, and they are fully editable at
runtime. You don't have to manage the "pointers", because these pre-written implementations do all the hard work
and just give you ways of doing the operations abstractly.

In Clojure the `list` function can be used to make a list, and the `cons` function can be used to make a
*new* list whose *tail* is some existing list. The reason for this is that in Clojure once data is created, it
is not allowed to be changed. This had all sorts of advantages which we will discuss later, but it means that
Clojure lists don't allow "middle of the list" inserts.

So in Clojure:

[source]
-----
(def list1 (list 1 2 3))
-----

[ditaa,target=list1]
-----
        +---+   +---+   +---+
list1 ->| 1 +-->| 2 +-->| 3 +-> ø
        +---+   +-+-+   +-+-+
-----

makes a new linked list called list1.

and this:

[source]
-----
(def list2 (cons 10 list1))
-----

makes a new NODE and points it at the other list:

[ditaa,target=list2]
-----
        +---+   +---+   +---+
list1 ->| 1 +-->| 2 +-->| 3 +-> ø
        +---+   +-+-+   +-+-+
          ^
          |
          +----+
               |
        +---+  |
list2 ->| 10+--+
        +---+
-----

In data structure theory this is known as *structural sharing*, and
has two advantages:

* Users of `list1` can *absolutely rely* on the value of the list *never*
changing at runtime. There is no operation that can corrupt that value. The
"name" `list1` could technically be re-bound to point at some completely
*new* value, but anyone that has the original list can trust it not to change. In languages like Java, lists are *mutable*, meaning that a program
has no such guarantees, and that is a common source of problems
and confusion.
* New lists can be based on old ones, saving memory. The runtime of
the program *looks* like it has a list of length 3, and a different list
of length 4; however, the truth is that it has one list with *two names*
that happen to be bound to different locations within the same list!

QUIZ::
Why can't Clojure allow you to put things at the end of an existing list?

BONUS::
What (conceptually, not as code) would you need to do to make a
new list in Clojure that had a new item at the *end*?

=== Maps a.k.a. Dictionaries

So far we've seen two data structures (arrays and lists) which store
things linearly. Arrays give direct indexed access, and lists require
a linear walk. Arrays are expensive to expand, but lists can be
expanded (in some ways) at lower expense.

But what about the case of a simple English Dictionary? Historically
we've built those by alphabetizing the words and storing them in
linear order, right?

So, technically we could use an array or list to make such a thing,
but there are some problems with doing that.

An array, for example, must have *equal-sized* elements (remember that
the indexed access requires jumping to a calculation position in memory
based on the element size). We could store just the word and a pointer
to a string at each array element:

[ditaa,target=arrayofpointers]
-----
offset +----+
    0  |  a |--> "definition"
       +----+
    1  | ask|--> "definition"
       +----+
    2  | asp|--> "definition"
       +----+
         ...
-----

but then at least the word itself would have to fit in each element (so
there would be some wasted space for most entries).

QUIZ::
If our dictionary was structure as above, what would be the computational cost of putting in a new word (if we were trying to maintain a sorted order)?

QUIZ::
If you used a linked list instead of an array, what would that look like?

If the array is sorted, then one way of finding a definition is to search by what is known as a "binary search". A binary search is one where basically you look at the "middle" and see if you've gone too far or not. This lets you eliminate half of things at a time. Just imagine you are looking for the word "Joker" in a paper dictionary. You open the dictionary in the approximate middle, and see you've hit the word "knight". So, you ignore the latter half of the dictionary, and look in the rough middle of the other half. You find "dry". Now you eliminate the "earlier part" of that, split again, etc.  As a human you might tune this a bit (you might say "I know that J comes just before K, so I'll just page back a bit), but you get the general principle.

So, say our dictionary contains 1000 words, and we search it like the above. The first step eliminates 500 things. Then the next step eliminates another 250. Then 125, and so on. At some point it is faster just to do a linear walk of what remains, but at the limit this takes stem:[log_2 N] steps.

So, if we had 1 million words, such a search takes (in the very worst case) about stem:[\floor{log_2 1000000} = 19] steps, but many times we'll find the word earlier than that. Still, it is much faster than a pure linear search!

QUIZ::
Consider the answers to the two prior quiz questions. Now that you've seen binary search, what do you think of the possible linked-list implementation? Why?

Computer science has spent a lot of time thinking up alternative answers to this problem. Fortunately, they've been doing that for 70+ years so you don't have to invent these things, and modern progamming languages just "come with" various versions that are good for this task, in various different ways. Some are faster at lookups, some are faster at inserts, some behave better over time when there have been lots of edits, etc.  There are a *lot* of trade-offs that you could consider.

In Clojure, there is a general-purpose version of this data structure which can
be created using curly braces, where the "key" and "value" pairs are simply listed
in order:

[source]
-----
{"a" "definition1"
 "as" "definition2"
 "ask" "definition3"}
-----

Javascript uses a similar but more limited version that looks very similar:

[source,javascript]
-----
{"a": "definition1",
 "as": "definition2",
 "ask": "definition3"}
-----

and if you're curious what it looks like in Java (and many other similar languages), it is something like this:

[source,java]
-----
HashMap<String, String> m = new HashMap<String, String>();
m.put("a", "definition1");
m.put("as", "definition2");
m.put("ask", "definition3");
-----

Notice that in Javascript the "key" always has to be a string, but in Clojure the key can be absolutely anything. Also notice that in Java there is no short/concise way to type out a map.  You have to make one (that's what `new` does), and then stick
things in one-at-a-time.

General-purpose maps typically have the following characteristics:

* Adding an entry takes time proportional to the stem:[log N] where N is the number of things already in the map.
* Removing an entry is similar.
* The *overhead* (cost of the data structure's management) for storing things is relatively low.

As such, maps are a great way to organize data that needs to be accessed

In most languages (Java, Javascript, C++, etc.) maps are mutable. You can change their content dynamically. This has the same potential problems we discussed with linked lists.

Maps in Clojure, like linked lists in Clojure, are immutable. They cannot be changed once created. However, they have the same exact benefits as lists: the way they are constructed allows for structural sharing, so creating a new version of a map with some difference is a very fast operation, which is also very efficient on space.

Creating a new map from an old one, where you want to add entries, can be done with `assoc`:

[source]
-----
(def m1 {"a" "definition1"})
(def m2 (assoc m1
          "as" "definition2"
          "ask" "definition3")
-----

QUIZ::
If you run the two things in the prior code block, and then look at the value of `m1`, what would you expect to be in there?

But in Java, for example, you can change the map in-place as you saw in the prior Java code block.

You'll learn some additional ways of working with maps in this section's exercises.

BONUS::
We mentioned earlier that maps in Clojure can use anything for keys and values. Can you think of a few different places where something other than strings as keys would be useful?

==== Clojure Keywords

This is a good time to talk about Clojure *keywords*. Remember when we talked about storing the "words" of the dictionary in an array earlier? The weakness, as you recall, was a bit of wasted space, but we actually didn't mention another downside: When you are searching for a word, you have to ask the computer to compare the word you want with the word that is in the dictionary, right? I mean how else will it know if it has found what you want?

Remember that strings are just arrays of characters. So, if we're looking for the word "knight" in our map, each step of the search has to do a character-by-character comparison (because that is all a CPU can actually do!).

This means that a string comparison is an O(N) algorithm! The longer the word, and the more times we have to compare it, the worse things get.

.Comparing two strings. We have to do three comparisons to prove these are not the same.
[ditaa]
-----
   +---+---+---+---+---+---+---+
   | K | N | I | G | H | T | ø |
   +---+---+---+---+---+---+---+
     |   |
     |   |   ≠
     |   |
   +---+---+---+---+---+
   | K | N | O | W | ø |
   +---+---+---+---+---+
-----

But what if there were a way for us to pre-encode something with human meaning into a number? That would mean that we could store our dictionary keyed by *numbers*, and then when we want to search we could encode our desired word into a number first, and do the search that way. This could be an improvement in performance, while also not really limiting our expressiveness.

QUIZ::
What does this last sentence mean by expressiveness?  I.e. Why does encoding an arbitrary string as a single number help expressiveness?

Of course there's a limitation: you would not want to encode all the possible strings in the world as numbers, because that would require an arbitrarily large amount of space, and huge numbers! So, we've been leading you astray just a bit. We do *not* use keywords as a way to, say, encode the English language words in a map of the English Language Dictionary. In fact, we _would_ actually use strings as the keys in this case because it is cost-prohibitive to encode all of English as pre-defined numbers. But hopefully, you've kind of seen the goal: when we are representing arbitrary, but semantically distinct, values within a map it is nice to have an efficient way to give a key an arbitrary name that cal also behave better at runtime.

Thus, the purpose of keywords is just that: To allocate numbers for names that you want to use for your program's data.

In Clojure, keywords start with a `:`, and are followed by an optional _namespace_ (a dot-separated sequence of glyphs), an optional `/` to indicate the end of the namespace, and then more non-whitespace glyphs for the name.

Some examples are `:name`, `:something/other`, and `com.google/search-string`.

The *namespace* of a keyword is meant as a means of categorization, and the name is meant as a means of identity. For example, let's say you want to store details about a person.  If you just used the keyword `:name` then it is ambiguous if you mean a person's name, or a place's name, or a dog's name. The namespace allows us to clarify our intended meaning:

[source]
-----
{:name "Fido"}

{:dog/name "Fido"}

{:person/name "Allison"}
-----

The underlying maps in all of these cases will encode the keyword into an efficient constant value that is fast to compare, but it maintains the readability and meaning to you the programmer!

The namespace also makes it possible to put related keys into the same map, even if they have the same "name" portion:

[source]
-----
{:person/name "Allison"
 :dog/name "Fido"
 :cat/name "Max"}
-----

NOTE: There is a recommendation if you write software in Clojure that might be used by others. The recommendation is that for any data that can be seen by other programmers, you should use namespaces for your keywords that contain a reverse domain name that you own (or perhaps uses a reverse domain name that clarifies the context of the information). Some examples might include `:com.google/search-string`, `:gov.us.irs/social-security-number`. These help ensure that if multiple programmers place data into the same map that they don't accidentally overwrite each other!

QUIZ::
Say you want to represent a 3d cartesian coordinate in Clojure. Give some examples of different ways you might use maps to do that. Of the examples you generate, indicate the circumstances where you might choose that one over any others. Hints: would you use namespaces? What kinds of numbers might you use?

=== Sets

A set is a mathematical construct that has a well established set of useful operations. As a data structure a set is a collection of items where duplicates are not allowed. The performance characteristics are such that adding, removing, and asking "is this value in the set?" are fast operations.

In Clojure these are created using curly braces as well, but by prefixing them with the `#` character.

[source]
-----
#{1 2 :a "hello"}
-----

They can contain any kind of value.

One of the primary operations on a set in Clojure is `contains?`:

[source]
-----
(contains? #{1 2 3} 1)
-----

which returns true if the item is in the set, and false otherwise.  There are, of course, set operations from mathematics like union, subtraction (or difference), intersection, etc.

Sets are not nearly as commonly used as maps, but they do come up with regularity.

NOTE: Sets are usually unordered (you can make sorted ones if you want, but that isn't the default).

=== Vectors

Clojure has an additional type that is similar in behavior to an array called a `vector`.  Internally it has a rather complex implementation that is meant to give performance that gets reasonably close to that of an array, with none of the drawbacks, all while have that same immutable guarantee that all the other Clojure data structures have!

We write vectors use square brackets, with space between each item like this:

[source]
-----
[1 2 3 :a "hello" 42.5]
-----

as you can see vectors can hold any kind of data.

Making a new vector with an item changed is done just like with maps, using `assoc`, but instead of the map entry key, we give an offset like for arrays:

[source]
-----
(def a [1 2 3])
(def b (assoc a 1 :x))
-----

QUIZ::
What's in `a` after this code runs?

QUIZ::
What's in `b` after this code runs?

You can pull a value from a vector with the same function you use on maps (`get`). You just use an offset
as the "key":

[source]
-----
(get a 1)
-----

The exercises will let you experiment more with vectors.

== Nesting Data

Now that we've got the general idea of what data structures are, we should talk more about the fact that they can be combined with each other. Languages like Clojure and Javascript are  particularly good at this because the values in their data structures can be anything. Some programming languages require the programmer to be more specific about what they put in a data structure. There are good reasons for both, actually. In languages like Clojure the general philosophy is that the power of the flexibility is better, whereas languages that have the programmer pre-declare what will go inside a data structure are easier to build tools for that can detect certain classes of errors early.

There are continuous debates about which approach is "right", and as with any such debate the answer is almost certainly "it depends". An experienced developer who has worked with both is often hard-pressed to define exactly when they would choose one over the other with objective criteria.

One place where Clojure's approach has some clear wins is when representing data. The ease and clarity you can get for a relatively complex bit of data, while also ensuring a measured amount of correctness, is quite good.

Consider an example. Let's try to do the exact same thing in Java and Clojure just to get an idea of the basic difference just in readability. First, Clojure:

[source]
-----
{:person/name "Sam"
 :person/age 22
 :person/address {:address/street "123 Main"}}
-----

and now the Java (note the use of Object, which is how you tell Java you want to be able to
use "anything". Technically, this is about as close to a 1-to-1 comparison of the exact same operations.

[source, java]
-----
HashMap<Object, Object> person = new HashMap<Object,Object>();
HashMap<Object, Object> addr = new HashMap<Object,Object>();
person.put("person/name", "Sam");
person.put("person/age", 22);
person.put("person/address", addr);
addr.put("address/street", "123 Main");
-----

However, if you were doing it the "right way", one might argue it would look like this (even this is shorter than what most Java programmers would write):

[source, java]
-----
class Person {
  public String name;
  public int age;
  public Address address;

  public Person(String name, String age) {
    this.name = name;
    this.age = age;
  }

  public void setAddress(Address a) {this.address = a;}
}

class Address {
  public String street;

  public Address(String street) { this.street = street; }
}

...

Person p = new Person("Sam", 22);
Address a = new Address("123 Main");
p.address = a;
-----

In other words, in languages like Java you have to "pre-define" what your data will look like in great detail (what everything will be named and what type it will have). This results in quite an explosion of detail that the programmer must write just to create some simple nested data! The other problem is that it lacks flexibility. You have to go back and change the definition if you happen to need to carry around some extra fact. Whereas in Clojure you can just put it in there whenever the need arises:

[source]
-----
(assoc person :person/salary 10300)
-----

=== Some Examples

One of the main tasks in programming is translating what you want in the real world into something that you can work on in a computer. In Clojure the ease of data nesting usually makes this relatively easy.

If you need a collection of named values, you use a map.

If you need a sequential collection of arbitrary things, you typically use a vector.

If you need to ensure that a collection of arbitrary things is unique you usually use a set.

For example, here's how you might represent a profile for a person in a dating app:

[source]
-----
{:member/id 902
 :member/alias "Happy Singer"
 :member/gender :male
 :member/birth-year 2000
 :member/seeking #{:friends :activity-partner}
 :member/messages [{:message/time "12:31pm"
                    :message/recipient {:member/id 42}
                    :message/content "Hi, how are you?"} ...]
 :member/interests #{{:interst/label "singing"} {:interest/label "dancing"}}}
-----

Here we use sets for "seeking" and "interests" because it would be silly to accidentally claim you're seeking "friends" and "friends", or that you're interested in "singing", "dancing", and "singing". But, we choose a vector for the message history, since no two messages will be completely identical (they happen over time), and we often want to review them in that order.



== Functional Programming Workhorses

Functional programming languages leverage the idea of sequences quite a bit. Sequences
of operations, sequences of values, etc. The actual underlying data structure could
be an array, a linked list, a map, or really anything that can be turned into items that
come one after another.

When you have such a sequence of values you will be surprised at how many different problems
can be solved by a very small number of programming language primitives. By far the
most important are:

map::
An operation that converts one sequence into a different sequence of exactly the same length as
the original.

filter::
An operation that returns a new sequence of just the elements of the input sequence that
match some condition.

reduce::
An operation that combines the elements of the sequence together into a single final result.

=== Mapping a sequence

Mapping a sequence is a very simple operation that can be described like this:

[ditaa,target=mapseq]
-----
   +---+ +---+ +---+ +---+
   | A | | B | | C | | D |  ...
   +-+-+ +-+-+ +-+-+ +-+-+
     |     |     |     |
     v     v     v     v
   +---+ +---+ +---+ +---+
   | l | | m | | n | | o |  ...
   +---+ +---+ +---+ +---+
-----

where the down-pointing arrows are defined as a function that can convert the values
in the top sequence to the values in the bottom. There are *no* restrictions
on what this function does. For example, it could nest the values from the top into
complex data structures, and thus the result would be a sequence of these
new complex data structures.

==== Clojure Example

So, say you wanted to create a sequence of Clojure maps that look like this:

[source]
-----
[{:x 1 :y 2}
 {:x 2 :y 3}
 {:x 3 :y 4}
 {:x 4 :y 5}]
-----

you might notice that the y value is always just one more than the x. So, if you create a simple
sequence of numbers, you can use `map`:

[source]
-----
(map
  (fn [n] {:x n :y (+ 1 n)})
  [1 2 3 4])
-----

It turns out that clojure can accept more than one sequence for map, and you can just increase
the number of arguments to the function. In this case ALL of the sequences are walked together,
giving the corresponding elements to the function. For example:

[source]
----
(map
  (fn [item-from-a item-from-b]
    (+ item-from-a item-from-b))
  [1 2 3]
  [10 11 12])
----

results in the sequence 11, 13, 15.

=== Filtering a Sequence

Very often an input sequence will contain values that you want, and those you do not. The point of
filtering a sequence therefore is defined to look basically like this:

[ditaa,target=filterseq]
-----
   +---+ +---+ +---+ +---+
   | A | | B | | C | | D |  ...
   +-+-+ +-+-+ +-+-+ +-+-+
     |           |
     v           v
   +---+       +---+
   | A |       | C |
   +---+       +---+
-----

the output sequence is still a sequence, it is just a "selection" of items from the original.

==== Clojure Example

[source]
-----
(filter (fn [n] (odd? n)) [1 2 3 4])
-----

results in:

[source]
-----
[1 3]
-----

=== Reducing a Sequence

Reduce is a real powerhouse operation. Mathematically, the idea is very simple. The inputs
are:

* A starting value.
* A function that can combine two values into one.
* A sequence of additional values.

The operation then proceeds as follows. Let `start` be the starting value. Let stem:[S_n] be the
nth element of the additional values. Let stem:[V_n] be the (internal temporary) value of the
reduction (so far). Then, the reduction of m elements looks like this:

[stem]
++++
V_1 = "combine"("start", S_1)

V_2 = "combine"(V_1, S_2)

V_3 = "combine"(V_2, S_3)

V_m = "combine"(V_{m-1}, S_m)
++++

For example, let's say the `combine` function was addition, the
starting value was 0, and the sequence was  4, 5, 6. The reduction would be:

[stem]
++++
4 = add(0, 4)

9 = add(4, 5)

15 = add(9, 6)
++++

so the answer of the reduction would be 15.

The sequence values can be *anything*, as can the *operation* (as long as the operation can
successfully combine the two things it receives, and returns something that can
be used as the first argument of the combine operation on the next step).

IMPORTANT: The result is a single *thing*, but that *thing* can be anything (e.g. a collection, primitive, etc.)

==== Clojure Example

In Clojure the `reduce` function takes the combine operation, the starting value, then the sequence.

[source]
-----
(reduce
  (fn [a b] (+ a b))
  0
  [4 5 6])
-----

but since `+` is already a function that can take two arguments, you can shorten this to:

[source]
-----
(reduce + 0 [4 5 6])
-----

because the starting value and result can be anything, it is actually possible to
use `reduce` to build up new sequences.

To demonstrate this we'll tell you about the `conj` function. This function
just adds an element to the end of a vector. For example,
`(conj [] 1)` => `[1]` and `(conj [1] 2)` => `[1 2]`, `(conj [1 2] 3)` => `[1 2 3]` etc.

So we can use this to have reduce actually build a sequence:

[source]
-----
(reduce
  (fn [a b]
    (conj a (+ 1 b)))
  []
  [1 2 3])
-----

QUIZ::
What is the output of the example? What have you seen before that this is equivalent to?

== Classes and Objects
